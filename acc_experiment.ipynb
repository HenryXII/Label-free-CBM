{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8843f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a6a1aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept-Class Matrix:\n",
      "Concepts \\ Classes: airplane automobile bird cat deer dog frog horse ship truck\n",
      "a Hunter             0 0 0 0 1 0 0 0 0 0\n",
      "a barn               0 0 0 0 0 0 0 1 0 0\n",
      "a beak               0 0 1 0 0 0 0 0 0 0\n",
      "a bed                0 0 0 0 0 1 0 0 0 0\n",
      "a bed for carrying cargo 0 0 0 0 0 0 0 0 0 1\n",
      "a beetle             0 0 0 0 0 0 1 0 0 0\n",
      "a bird feeder        0 0 1 0 0 0 0 0 0 0\n",
      "a birdfeeder         0 0 1 0 0 0 0 0 0 0\n",
      "a birdhouse          0 0 1 0 0 0 0 0 0 0\n",
      "a bit                0 0 0 0 0 0 0 1 0 0\n",
      "a boat               0 0 0 0 0 0 0 0 1 0\n",
      "a branch             0 0 1 0 0 0 0 0 0 0\n",
      "a bridle             0 0 0 0 0 0 0 1 0 0\n",
      "a cab for the driver 0 0 0 0 0 0 0 0 0 1\n",
      "a cage               0 0 1 0 0 0 0 0 0 0\n",
      "a captain            0 0 0 0 0 0 0 0 1 0\n",
      "a cat bed            0 0 0 1 0 0 0 0 0 0\n",
      "a cat food dish      0 0 0 1 0 0 0 0 0 0\n",
      "a cat toy            0 0 0 1 0 0 0 0 0 0\n",
      "a collar             0 0 0 0 0 1 0 0 0 0\n",
      "a copilot            1 0 0 0 0 0 0 0 0 0\n",
      "a crew               0 0 0 0 0 0 0 0 1 0\n",
      "a dashboard          0 1 0 0 0 0 0 0 0 1\n",
      "a deck               0 0 0 0 0 0 0 0 1 0\n",
      "a deer stand         0 0 0 0 1 0 0 0 0 0\n",
      "a dock               0 0 0 0 0 0 0 0 1 0\n",
      "a dog bowl           0 0 0 0 0 1 0 0 0 0\n",
      "a driver             0 1 0 0 0 0 0 0 0 1\n",
      "a field              0 0 0 0 1 0 0 0 0 0\n",
      "a flat back end      0 0 0 0 0 0 0 0 1 0\n",
      "a flat front and back 0 0 0 0 0 0 0 0 0 1\n",
      "a flight attendant   1 0 0 0 0 0 0 0 0 0\n",
      "a fly                0 0 0 0 0 0 1 0 0 0\n",
      "a food bowl          0 0 0 0 0 1 0 0 0 0\n",
      "a forest             0 0 0 0 1 0 0 0 0 0\n",
      "a four-legged mammal 0 0 0 0 0 1 0 0 0 0\n",
      "a gear shift         0 0 0 0 0 0 0 0 0 1\n",
      "a green or brown body 0 0 0 0 0 0 1 0 0 0\n",
      "a grille             0 0 0 0 0 0 0 0 0 1\n",
      "a halter             0 0 0 0 0 0 0 1 0 0\n",
      "a hitch              0 0 0 0 0 0 0 0 0 1\n",
      "a large body         0 0 0 0 0 0 0 1 0 0\n",
      "a large size         0 0 0 0 0 0 0 0 1 0\n",
      "a large, metal body  1 1 0 0 0 0 0 0 0 0\n",
      "a large, rectangular body 0 0 0 0 0 0 0 0 0 1\n",
      "a lead rope          0 0 0 0 0 0 0 1 0 0\n",
      "a leaf               0 0 1 0 0 0 0 0 0 0\n",
      "a leash              0 0 0 0 0 1 0 0 0 0\n",
      "a lily pad           0 0 0 0 0 0 1 0 0 0\n",
      "a litter box         0 0 0 1 0 0 0 0 0 0\n",
      "a long neck          0 0 0 0 1 0 0 1 0 0\n",
      "a mane and tail      0 0 0 0 0 0 0 1 0 0\n",
      "a mast               0 0 0 0 0 0 0 0 1 0\n",
      "a mosquito           0 0 0 0 0 0 1 0 0 0\n",
      "a nest               0 0 1 0 0 0 0 0 0 0\n",
      "a net                0 0 0 0 0 0 1 0 0 0\n",
      "a nose               0 0 0 0 0 1 0 0 0 0\n",
      "a passenger          1 1 0 0 0 0 0 0 0 0\n",
      "a pasture            0 0 0 0 0 0 0 1 0 0\n",
      "a pedal              0 1 0 0 0 0 0 0 0 0\n",
      "a person             0 0 0 0 0 1 1 0 0 0\n",
      "a pilot              1 0 0 0 0 0 0 0 0 0\n",
      "a pointed front end  0 0 0 0 0 0 0 0 1 0\n",
      "a pond               0 0 0 0 0 0 1 0 0 0\n",
      "a port               0 0 0 0 0 0 0 0 1 0\n",
      "a reddish-brown coat 0 0 0 0 1 0 0 0 0 0\n",
      "a reins              0 0 0 0 0 0 0 1 0 0\n",
      "a rider              0 0 0 0 0 0 0 1 0 0\n",
      "a rifle              0 0 0 0 1 0 0 0 0 0\n",
      "a road               0 1 0 0 0 0 0 0 0 1\n",
      "a rudder             0 0 0 0 0 0 0 0 1 0\n",
      "a runway             1 0 0 0 0 0 0 0 0 0\n",
      "a saddle             0 0 0 0 0 0 0 1 0 0\n",
      "a scratching post    0 0 0 1 0 0 0 0 0 0\n",
      "a seat               0 1 0 0 0 0 0 0 0 0\n",
      "a seatbelt           0 1 0 0 0 0 0 0 0 1\n",
      "a short, stocky build 0 0 0 0 0 0 1 0 0 0\n",
      "a slender body       0 0 0 0 1 0 0 0 0 0\n",
      "a small, lithe body  0 0 0 1 0 0 0 0 0 0\n",
      "a spider             0 0 0 0 0 0 1 0 0 0\n",
      "a steering wheel     0 1 0 0 0 0 0 0 0 1\n",
      "a suitcase           1 0 0 0 0 0 0 0 0 0\n",
      "a tail               1 0 0 1 0 1 0 0 0 0\n",
      "a tire               0 1 0 0 0 0 0 0 0 1\n",
      "a tough, durable frame 0 0 0 0 0 0 0 0 0 1\n",
      "a toy                0 0 0 0 0 1 0 0 0 0\n",
      "a trailer            0 0 0 0 0 0 0 0 0 1\n",
      "a tree               0 0 1 0 0 0 0 0 0 0\n",
      "a wet nose           0 0 0 0 0 1 0 0 0 0\n",
      "a wheel              0 1 0 0 0 0 0 0 0 1\n",
      "a wide mouth         0 0 0 0 0 0 1 0 0 0\n",
      "a windshield         0 1 0 0 0 0 0 0 0 0\n",
      "a worm               0 0 1 0 0 0 0 0 0 0\n",
      "amphibian            0 0 0 0 0 0 1 0 0 0\n",
      "an engine            0 1 0 0 0 0 0 0 0 0\n",
      "animal               0 0 1 1 1 1 1 1 0 0\n",
      "antlers              0 0 0 0 1 0 0 0 0 0\n",
      "cargo                0 0 0 0 0 0 0 0 1 0\n",
      "engines              1 0 0 0 0 0 0 0 0 0\n",
      "engines on the wings 1 0 0 0 0 0 0 0 0 0\n",
      "feathers             0 0 1 0 0 0 0 0 0 0\n",
      "food                 0 0 0 0 0 1 0 0 0 0\n",
      "four legs            0 0 0 1 0 1 0 1 0 0\n",
      "four round, black tires 0 1 0 0 0 0 0 0 0 0\n",
      "four wheels          0 0 0 0 0 0 0 0 0 1\n",
      "fur                  0 0 0 1 0 1 0 0 0 0\n",
      "grass                0 0 0 0 1 0 0 0 0 0\n",
      "hooves               0 0 0 0 1 0 0 1 0 0\n",
      "insects              0 0 0 0 0 0 1 0 0 0\n",
      "landing gear         1 0 0 0 0 0 0 0 0 0\n",
      "large sails or engines 0 0 0 0 0 0 0 0 1 0\n",
      "large, brown eyes    0 0 0 0 1 0 0 0 0 0\n",
      "large, bulging eyes  0 0 0 0 0 0 1 0 0 0\n",
      "lily pads            0 0 0 0 0 0 1 0 0 0\n",
      "living thing         0 0 1 0 0 1 0 0 0 0\n",
      "long ears            0 0 0 0 1 0 0 0 0 0\n",
      "long hind legs for jumping 0 0 0 0 0 0 1 0 0 0\n",
      "long, thin legs      0 0 0 0 1 0 0 0 0 0\n",
      "machine              0 1 0 0 0 0 0 0 0 0\n",
      "mammal               0 0 0 1 1 1 0 1 0 0\n",
      "multiple decks       0 0 0 0 0 0 0 0 1 0\n",
      "multiple sails       0 0 0 0 0 0 0 0 1 0\n",
      "nature               0 0 0 0 1 0 0 0 0 0\n",
      "object               1 1 0 0 0 0 0 0 1 1\n",
      "organism             0 0 0 0 0 1 0 0 0 0\n",
      "passengers           0 0 0 0 0 0 0 0 1 0\n",
      "pointed ears         0 0 0 1 0 1 0 0 0 0\n",
      "quadruped            0 0 0 0 0 0 0 1 0 0\n",
      "side windows         0 1 0 0 0 0 0 0 0 0\n",
      "taillights           0 1 0 0 0 0 0 0 0 0\n",
      "the ability to fly   0 0 1 0 0 0 0 0 0 0\n",
      "the ocean            0 0 0 0 0 0 0 0 1 0\n",
      "transportation       0 1 0 0 0 0 0 0 1 1\n",
      "trees                0 0 0 0 1 0 0 0 0 0\n",
      "two headlights       0 0 0 0 0 0 0 0 0 1\n",
      "vertebrate           0 0 1 1 1 1 1 1 0 0\n",
      "vessel               0 0 0 0 0 0 0 0 1 0\n",
      "watercraft           0 0 0 0 0 0 0 0 1 0\n",
      "webbed feet          0 0 0 0 0 0 1 0 0 0\n",
      "whiskers             0 0 0 1 0 0 0 0 0 0\n",
      "white spots on the coat 0 0 0 0 1 0 0 0 0 0\n",
      "wings                1 0 1 0 0 0 0 0 0 0\n",
      "woods                0 0 0 0 1 0 0 0 0 0\n",
      "\n",
      "Does 'a pilot' belong to 'airplane'? True\n"
     ]
    }
   ],
   "source": [
    "dataset=\"cifar10\"\n",
    "concept_set=\"data/concept_sets/{}_filtered.txt\".format(dataset)\n",
    "\n",
    "#get concept set\n",
    "cls_file = data_utils.LABEL_FILES[dataset]\n",
    "with open(cls_file, \"r\") as f:\n",
    "    classes = f.read().split(\"\\n\")\n",
    "    \n",
    "with open(concept_set) as f:\n",
    "    concepts = f.read().split(\"\\n\")\n",
    "\n",
    "# Function to read JSON files\n",
    "def read_json_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Read the JSON files\n",
    "file1 = read_json_file('data/concept_sets/gpt3_init/gpt3_{}_around.json'.format(dataset))\n",
    "file2 = read_json_file('data/concept_sets/gpt3_init/gpt3_{}_important.json'.format(dataset))\n",
    "file3 = read_json_file('data/concept_sets/gpt3_init/gpt3_{}_superclass.json'.format(dataset))\n",
    "\n",
    "# Create a matrix to store the relationships\n",
    "matrix = np.zeros((len(concepts), len(classes)), dtype=int)\n",
    "\n",
    "# Populate the matrix based on the JSON data\n",
    "for file in [file1, file2, file3]:\n",
    "    for class_index, class_name in enumerate(classes):\n",
    "        if class_name in file:\n",
    "            for concept in file[class_name]:\n",
    "                if concept in concepts:\n",
    "                    concept_index = concepts.index(concept)\n",
    "                    matrix[concept_index][class_index] = 1\n",
    "\n",
    "# Display the matrix\n",
    "print(\"Concept-Class Matrix:\")\n",
    "print(\"Concepts \\ Classes:\", *classes)\n",
    "for i, concept in enumerate(concepts):\n",
    "    print(f\"{concept:<20}\", *matrix[i])\n",
    "\n",
    "# You can also access the matrix programmatically\n",
    "# For example, to check if \"a pilot\" belongs to \"airplane\":\n",
    "pilot_index = concepts.index(\"a pilot\")\n",
    "airplane_index = classes.index(\"airplane\")\n",
    "print(f\"\\nDoes 'a pilot' belong to 'airplane'? {bool(matrix[pilot_index][airplane_index])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "755b8cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /home/jix049/.cache/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:05<00:00, 29848616.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/jix049/.cache/cifar-10-python.tar.gz to /home/jix049/.cache\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_utils.get_targets_only(dataset+\"_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf2b09ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original approach result:\n",
      "tensor([[ 0.,  2.,  3.,  0.],\n",
      "        [ 5.,  0.,  7.,  0.],\n",
      "        [ 9.,  0.,  0., 12.]])\n",
      "\n",
      "Optimized approach result:\n",
      "tensor([[ 0.,  2.,  3.,  0.],\n",
      "        [ 5.,  0.,  7.,  0.],\n",
      "        [ 9.,  0.,  0., 12.]])\n",
      "\n",
      "Results are identical: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Toy data setup\n",
    "clip_features = torch.tensor([\n",
    "    [1.0, 2.0, 3.0, 4.0],\n",
    "    [5.0, 6.0, 7.0, 8.0],\n",
    "    [9.0, 10.0, 11.0, 12.0]\n",
    "])\n",
    "\n",
    "concept_class_membership = torch.tensor([\n",
    "    [True, False, True],\n",
    "    [False, True, False],\n",
    "    [True, True, False],\n",
    "    [False, False, True]\n",
    "])\n",
    "\n",
    "image_class_indices = [1, 0, 2]\n",
    "\n",
    "# Original loop-based approach\n",
    "def original_approach(clip_features, concept_class_membership, image_class_indices):\n",
    "    num_images, num_concepts = clip_features.shape\n",
    "    mask = torch.zeros((num_images, num_concepts), dtype=torch.bool)\n",
    "    for i, class_index in enumerate(image_class_indices):\n",
    "        mask[i] = concept_class_membership[:, class_index]\n",
    "    return torch.where(mask, clip_features, torch.zeros_like(clip_features))\n",
    "\n",
    "# Optimized approach\n",
    "def optimized_approach(clip_features, concept_class_membership, image_class_indices):\n",
    "    class_indices_tensor = torch.tensor(image_class_indices)\n",
    "    mask = concept_class_membership[:, class_indices_tensor].T\n",
    "    return torch.where(mask, clip_features, torch.zeros_like(clip_features))\n",
    "\n",
    "# Run both approaches\n",
    "result_original = original_approach(clip_features, concept_class_membership, image_class_indices)\n",
    "result_optimized = optimized_approach(clip_features, concept_class_membership, image_class_indices)\n",
    "\n",
    "# Print results\n",
    "print(\"Original approach result:\")\n",
    "print(result_original)\n",
    "print(\"\\nOptimized approach result:\")\n",
    "print(result_optimized)\n",
    "\n",
    "# Check if results are identical\n",
    "print(\"\\nResults are identical:\", torch.all(result_original == result_optimized).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f34ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ /datasets/imagenet-ilsvrc2012 exists\n",
      "✓ /datasets/imagenet-ilsvrc2012 is readable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "address = \"/datasets/imagenet-ilsvrc2012\"\n",
    "\n",
    "if os.path.exists(address):\n",
    "    print(f\"✓ {address} exists\")\n",
    "    if os.access(address, os.R_OK):\n",
    "        print(f\"✓ {address} is readable\")\n",
    "    else:\n",
    "        print(f\"✗ {address} is not readable\")\n",
    "else:\n",
    "    print(f\"✗ {address} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b6dadd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets, transforms, models\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/jupyter/kernels/lekernel/lib/python3.9/site-packages/torchvision/datasets/folder.py:328\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    321\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    326\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    327\u001b[0m ):\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[0;32m~/.local/share/jupyter/kernels/lekernel/lib/python3.9/site-packages/torchvision/datasets/folder.py:150\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m    149\u001b[0m classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_classes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot)\n\u001b[0;32m--> 150\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextensions \u001b[38;5;241m=\u001b[39m extensions\n",
      "File \u001b[0;32m~/.local/share/jupyter/kernels/lekernel/lib/python3.9/site-packages/torchvision/datasets/folder.py:203\u001b[0m, in \u001b[0;36mDatasetFolder.make_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_to_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m# prevent potential bug since make_dataset() would use the class_to_idx logic of the\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# find_classes() function, instead of using that of the find_classes() method, which\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# is potentially overridden and thus could have a different logic.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe class_to_idx parameter cannot be None.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_empty\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/jupyter/kernels/lekernel/lib/python3.9/site-packages/torchvision/datasets/folder.py:89\u001b[0m, in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(target_dir):\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m root, _, fnames \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwalk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollowlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(fnames):\n\u001b[1;32m     91\u001b[0m         path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, fname)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/os.py:367\u001b[0m, in \u001b[0;36m_walk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 367\u001b[0m         entry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscandir_it\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms, models\n",
    "data = datasets.ImageFolder(\n",
    "            root=os.path.join(address, 'training'),\n",
    "            transform=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadccd4d",
   "metadata": {},
   "source": [
    "### acc check json correct for concept list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c87c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Results:\n",
      "--------------------------------------------------\n",
      "✓ All concepts are included in the classifications!\n",
      "\n",
      "Concept Usage Statistics:\n",
      "--------------------------------------------------\n",
      "Concepts by frequency of use:\n",
      "- a brown body: 6 class(es)\n",
      "- animal: 6 class(es)\n",
      "- organism: 6 class(es)\n",
      "- a large body: 4 class(es)\n",
      "- a leaf: 4 class(es)\n",
      "- a nose: 4 class(es)\n",
      "- a tail: 4 class(es)\n",
      "- a wet nose: 4 class(es)\n",
      "- food: 4 class(es)\n",
      "- four legs: 4 class(es)\n",
      "- fur: 4 class(es)\n",
      "- large, brown eyes: 4 class(es)\n",
      "- machine: 4 class(es)\n",
      "- nature: 4 class(es)\n",
      "- a large size: 3 class(es)\n",
      "- a seat: 3 class(es)\n",
      "- a steering wheel: 3 class(es)\n",
      "- a tough, durable frame: 3 class(es)\n",
      "- a windshield: 3 class(es)\n",
      "- side windows: 3 class(es)\n",
      "- two headlights: 3 class(es)\n",
      "- a cab for the driver: 2 class(es)\n",
      "- a cage: 2 class(es)\n",
      "- a dashboard: 2 class(es)\n",
      "- a driver: 2 class(es)\n",
      "- a field: 2 class(es)\n",
      "- a food bowl: 2 class(es)\n",
      "- a grille: 2 class(es)\n",
      "- a large, metal body: 2 class(es)\n",
      "- a leash: 2 class(es)\n",
      "- a long neck: 2 class(es)\n",
      "- a pet food dish: 2 class(es)\n",
      "- a pet toy: 2 class(es)\n",
      "- a road: 2 class(es)\n",
      "- a slender body: 2 class(es)\n",
      "- a tire: 2 class(es)\n",
      "- a toy: 2 class(es)\n",
      "- a wheel: 2 class(es)\n",
      "- cargo: 2 class(es)\n",
      "- four wheels: 2 class(es)\n",
      "- grass: 2 class(es)\n",
      "- hooves: 2 class(es)\n",
      "- long ears: 2 class(es)\n",
      "- long, thin legs: 2 class(es)\n",
      "- pointed ears: 2 class(es)\n",
      "- taillights: 2 class(es)\n",
      "- the ability to fly: 2 class(es)\n",
      "- whiskers: 2 class(es)\n",
      "- wings: 2 class(es)\n",
      "- a barn: 1 class(es)\n",
      "- a beak: 1 class(es)\n",
      "- a birdfeeder: 1 class(es)\n",
      "- a boat: 1 class(es)\n",
      "- a branch: 1 class(es)\n",
      "- a bridle: 1 class(es)\n",
      "- a captain: 1 class(es)\n",
      "- a cargo bed: 1 class(es)\n",
      "- a cat bed: 1 class(es)\n",
      "- a collar: 1 class(es)\n",
      "- a crew: 1 class(es)\n",
      "- a deck: 1 class(es)\n",
      "- a deer stand: 1 class(es)\n",
      "- a dock: 1 class(es)\n",
      "- a dog bed: 1 class(es)\n",
      "- a flat back end: 1 class(es)\n",
      "- a forest: 1 class(es)\n",
      "- a green body: 1 class(es)\n",
      "- a halter: 1 class(es)\n",
      "- a jet engine: 1 class(es)\n",
      "- a large, rectangular body: 1 class(es)\n",
      "- a litter box: 1 class(es)\n",
      "- a mane and tail: 1 class(es)\n",
      "- a mast: 1 class(es)\n",
      "- a nest: 1 class(es)\n",
      "- a pasture: 1 class(es)\n",
      "- a pointed front end: 1 class(es)\n",
      "- a pond: 1 class(es)\n",
      "- a port: 1 class(es)\n",
      "- a reddish-brown coat: 1 class(es)\n",
      "- a reins: 1 class(es)\n",
      "- a rider: 1 class(es)\n",
      "- a rudder: 1 class(es)\n",
      "- a runway: 1 class(es)\n",
      "- a saddle: 1 class(es)\n",
      "- a scratching post: 1 class(es)\n",
      "- a small, lithe body: 1 class(es)\n",
      "- a trailer: 1 class(es)\n",
      "- a wide mouth: 1 class(es)\n",
      "- antlers: 1 class(es)\n",
      "- feathers: 1 class(es)\n",
      "- landing gear: 1 class(es)\n",
      "- large sails: 1 class(es)\n",
      "- large, bulging eyes: 1 class(es)\n",
      "- lily pads: 1 class(es)\n",
      "- long hind legs for jumping: 1 class(es)\n",
      "- multiple sails: 1 class(es)\n",
      "- the ocean: 1 class(es)\n",
      "- trees: 1 class(es)\n",
      "- vessel: 1 class(es)\n",
      "- watercraft: 1 class(es)\n",
      "- webbed feet: 1 class(es)\n",
      "- white spots on the coat: 1 class(es)\n",
      "- woods: 1 class(es)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Dict, List, Set\n",
    "\n",
    "def validate_concepts(json_file_path: str, concepts_file_path: str) -> tuple[bool, Set[str], Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Validates if all concepts from a text file are included in a JSON classification file.\n",
    "    \n",
    "    Args:\n",
    "        json_file_path (str): Path to the JSON file containing class-concept mappings\n",
    "        concepts_file_path (str): Path to the text file containing concepts list\n",
    "    \n",
    "    Returns:\n",
    "        tuple containing:\n",
    "        - bool: True if all concepts are included, False otherwise\n",
    "        - Set[str]: Set of missing concepts\n",
    "        - Dict[str, int]: Dictionary showing how many times each concept appears in the classifications\n",
    "    \"\"\"\n",
    "    # Read the JSON file\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        classifications = json.load(f)\n",
    "    \n",
    "    # Read the concepts file\n",
    "    with open(concepts_file_path, 'r') as f:\n",
    "        # Read concepts, strip whitespace, and filter out empty lines\n",
    "        concepts = {line.strip() for line in f.readlines() if line.strip()}\n",
    "    \n",
    "    # Create a set of all concepts used in the JSON and count their occurrences\n",
    "    used_concepts: Set[str] = set()\n",
    "    concept_counts: Dict[str, int] = {}\n",
    "    \n",
    "    for class_name, class_concepts in classifications.items():\n",
    "        for concept in class_concepts:\n",
    "            used_concepts.add(concept)\n",
    "            concept_counts[concept] = concept_counts.get(concept, 0) + 1\n",
    "    \n",
    "    # Find missing concepts\n",
    "    missing_concepts = concepts - used_concepts\n",
    "    \n",
    "    # Check if any concepts in the JSON are not in the original concepts list\n",
    "    extra_concepts = used_concepts - concepts\n",
    "    if extra_concepts:\n",
    "        print(\"\\nWarning: Found concepts in JSON that are not in the concepts list:\")\n",
    "        for concept in sorted(extra_concepts):\n",
    "            print(f\"- {concept}\")\n",
    "    \n",
    "    return (len(missing_concepts) == 0, missing_concepts, concept_counts)\n",
    "\n",
    "def print_validation_results(all_included: bool, missing_concepts: Set[str], concept_counts: Dict[str, int]) -> None:\n",
    "    \"\"\"\n",
    "    Prints the validation results in a readable format.\n",
    "    \"\"\"\n",
    "    print(\"\\nValidation Results:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if all_included:\n",
    "        print(\"✓ All concepts are included in the classifications!\")\n",
    "    else:\n",
    "        print(\"✗ Some concepts are missing from the classifications:\")\n",
    "        for concept in sorted(missing_concepts):\n",
    "            print(f\"- {concept}\")\n",
    "    \n",
    "    print(\"\\nConcept Usage Statistics:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Concepts by frequency of use:\")\n",
    "    sorted_concepts = sorted(concept_counts.items(), key=lambda x: (-x[1], x[0]))\n",
    "    for concept, count in sorted_concepts:\n",
    "        print(f\"- {concept}: {count} class(es)\")\n",
    "\n",
    "\n",
    "json_path = \"data/concept_sets/cifar10_acc_claude.json\"\n",
    "concepts_path = \"data/concept_sets/cifar10_manual.txt\"\n",
    "\n",
    "try:\n",
    "    all_included, missing, counts = validate_concepts(json_path, concepts_path)\n",
    "    print_validation_results(all_included, missing, counts)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not find file - {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error: Invalid JSON file - {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: An unexpected error occurred - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8007af7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lekernel",
   "language": "python",
   "name": "lekernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
